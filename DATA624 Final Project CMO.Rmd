---
title: "DATA624 Beverage Manufacturing Modeling Final Project"
author: "Omar Pineda, Calvin Wong, Murali Kunissery"
date: "4/15/2020"
output: 
  flexdashboard::flex_dashboard:
    orientation: rows
    source_code: embed
---

Sidebar {.sidebar}
-------------------------------------

### Task

This is role playing. I am your new boss. I am in charge of production at ABC Beverage and you are a team of data scientists reporting to me. My leadership has told me that new regulations are requiring us to understand our manufacturing process, the predictive factors and be able to report to them our predictive model of PH.

Please use the historical data set I am providing. Build and report the factors in BOTH a technical and non-technical report.  I like to use Word and Excel. Please provide your non-technical report in a  business friendly readable document and your predictions in an Excel readable format. The technical report should show clearly the models you tested and how you selected your final approach.

Please submit both Rpubs links and .rmd files or other readable formats for technical and non-technical reports.  Also submit the excel file showing the prediction of your models for pH.

Row {.tabset .tabset-fade}
-------------------------------------

### Data

```{r}
library(caTools)
library(DMwR)
library(mlbench)
library(randomForest)
library(caret)
library(rpart)
library(xlsx)
library(psych)
```

First, we load our dataset and explore some of the statistics for our variables. 

```{r}
bev <- read.xlsx("StudentData.xlsx", sheetName = "Subset")
```

We have 2,571 samples and 32 features that we can use to train our predictive model of PH. Here are summary statistics for our features:

```{r}
describe(bev)
apply(bev,2,function(x) sum(is.na(x)))
```

We noticed that 4 samples had missing values for PH, so we decided to remove them from our analysis since we cannot use them to predict outcomes. This left us with 2,567 observations.

Next, we use KNN imputation which imputes a missing value with the average weighted value of observations near/similar to it. We perform this imputation for missing values in all variables except for the response variable, PH.

We also split our data into a training and test set, using 80% of our data to train our models and holding out 20% to test them.

```{r}
#removal of samples with missing PH values
bev <- bev[!is.na(bev$PH),]
bev_nl <- bev
```

```{r}
#imputations
bev_imp <- knnImputation(bev[, !names(bev) %in% "PH"])
bev_imp$PH <- bev$PH

#data splitting
set.seed(101) 
sample = sample.split(bev_imp$Brand.Code, SplitRatio = .8)
bev_train = subset(bev_imp, sample == TRUE)
bev_test  = subset(bev_imp, sample == FALSE)

bev_train_X = subset(bev_train, select = -PH)
bev_train_y = bev_train[,'PH']

bev_test_X = subset(bev_test, select = -PH)
bev_test_y = bev_test[,'PH']
```




### Linear Regression Model

### Non-linear Regression Models

In this section, we are going to fit a simple neural network using the neuralnet package and fit a linear model as a comparison.

```{r}
bdev <- bev_nl
#removal of samples with missing PH values
bev <- bev[!is.na(bev$PH),]
bevknn <- bev[!names(bev) %in% "Brand.Code"]
bevknn <- bevknn[!names(bevknn) %in% "PH"]

#imputations
bev_imp <- knnImputation(bevknn)
#bev_imp$Brand.Code <- bev$Brand.Code
bev_imp$PH <- bev$PH
data <- bev_imp
```

** Confirming that there are no more empty data **
```{r}
#describe(bev)
apply(data,2,function(x) sum(is.na(x)))
```
There is no missing data, good. We proceed by randomly splitting the data into a train and a test set, then we fit a linear regression model and test it on the test set. Note that I am using the gml() function instead of the lm() this will become useful later when cross validating the linear model.

```{r}
index <- sample(1:nrow(data),round(0.75*nrow(data)))
train <- data[index,]
test <- data[-index,]
lm.fit <- glm(PH~., data=train)
summary(lm.fit)
pr.lm <- predict(lm.fit,test)
MSE.lm <- sum((pr.lm - test$medv)^2)/nrow(test)
MSE.lm
```

The sample(x,size) function simply outputs a vector of the specified size of randomly selected samples from the vector x. By default the sampling is without replacement: index is essentially a random vector of indeces.
Since we are dealing with a regression problem, we are going to use the mean squared error (MSE) as a measure of how much our predictions are far away from the real data.

## Preparing to fit the neural network
Before fitting a neural network, some preparation need to be done.

As a first step, we are going to address data preprocessing. I will be normalizing the data before training a neural network.  I chose to use the min-max method and scale the data in the interval [0,1]. Usually scaling in the intervals [0,1] or [-1,1] tends to give better results.
We therefore scale and split the data before moving on:

```{r }

data
maxs <- apply(data, 2, max) 
mins <- apply(data, 2, min)

```
scaled returns a matrix that needs to be coerced into a data.frame.


```{r }

maxs <- apply(data, 2, max) 
mins <- apply(data, 2, min)
scaled <- as.data.frame(scale(data, center = mins, scale = maxs - mins))
scaled
train_ <- scaled[index,]
test_ <- scaled[-index,]

```

Parameters
As far as I know there is no fixed rule as to how many layers and neurons to use although there are several more or less accepted rules of thumb. Usually, if at all necessary, one hidden layer is enough for a vast numbers of applications. As far as the number of neurons is concerned, it should be between the input layer size and the output layer size, usually 2/3 of the input size. At least in my brief experience testing again and again is the best solution since there is no guarantee that any of these rules will fit your model best.
In this dataset, we are going to use 2 hidden layers with this configuration: 32:5:3:1. The input layer has 32 inputs, the two hidden layers have 5 and 3 neurons and the output layer has, of course, a single output since we are doing regression.
Letâ€™s fit the net: Setting the linear.output = True does regression instead of classification.

```{r }
library(neuralnet)
n <- names(train_)
f <- as.formula(paste("PH ~", paste(n[!n %in% "PH"], collapse = " + ")))
nn <- neuralnet(f,data=train_,hidden=c(5,3),linear.output=T)

```

### Plot the Neural Network
```{r   }
plot(nn)
```
The black lines show the connections between each layer and the weights on each connection while the blue lines show the bias term added in each step. The bias can be thought as the intercept of a linear model.
The net is essentially a black box so we cannot say that much about the fitting, the weights and the model. Suffice to say that the training algorithm has converged and therefore the model is ready to be used.

## Predicting PH  using the neural network
Now we can try to predict the values for the test set and calculate the MSE. The net will output a normalized prediction, so we need to scale it back in order to make a meaningful comparison (or just a simple prediction).

```{r   }
pr.nn <- compute(nn,test_[,1:32])
pr.nn_ <- pr.nn$net.result*(max(data$PH)-min(data$PH))+min(data$PH)
test.r <- (test_$PH)*(max(data$PH)-min(data$PH))+min(data$PH)
MSE.nn <- sum((test.r - pr.nn_)^2)/nrow(test_)
```

```{r   }
print(paste(MSE.lm,MSE.nn))
```
Apparently, the Linear Model is doing a better work than the Neural Network at predicting PH in this case as the MSE is 0 for the lm.


##Output Plot
```{r   }
plot(test$PH,pr.nn_,col='red',main='Real vs predicted NN',pch=18,cex=0.7)
points(test$PH,pr.lm,col='blue',pch=18,cex=0.7)
abline(0,1,lwd=2)
legend('bottomright',legend=c('NN','LM'),pch=18,col=c('red','blue'))
```



### Tree Models

In this next part, we consider various tree models to predict the PH of a beverage given our information about the 32 manufacturing features.

Basic Regression Tree:

```{r}
bevb <- train(x = bev_train_X, y = bev_train_y, method = "rpart")
bevb
```

```{r}
bevbPred <- predict(bevb, newdata = bev_test_X)
bevb.results <- postResample(pred = bevbPred, obs = bev_test_y)
bevb.results
```

Random Forest:

```{r}
bevrf <- train(x = bev_train_X, y = bev_train_y, method = "rf")
bevrf
```

```{r}
bevrfPred <- predict(bevrf, newdata = bev_test_X)
bevrf.results <- postResample(pred = bevrfPred, obs = bev_test_y)
bevrf.results
```

XGBoost:

XGBoost only manages numeric vectors, so we have to recode our Brand.Code feature into a number before tuning our model.

```{r}
bev_train_X2 <- bev_train_X
bev_train_X2$Brand.Code <- as.numeric(bev_train_X2$Brand.Code)

bevxgb <- train(x = bev_train_X2, y = bev_train_y, method = "xgbTree")
bevxgb
```

```{r}
bev_test_X2 <- bev_test_X
bev_test_X2$Brand.Code <- as.numeric(bev_test_X2$Brand.Code)

bevxgbPred <- predict(bevxgb, newdata = bev_test_X2)
bevxgb.results <- postResample(pred = bevxgbPred, obs = bev_test_y)
bevxgb.results
```

The results of these 3 models are summarized here:

```{r}
xgb <- as.data.frame(as.list(bevxgb.results))
basic <- as.data.frame(as.list(bevb.results))
rf <- as.data.frame(as.list(bevrf.results))
xgb$model <- 'XGBoost'
basic$model <- 'Basic Regression Tree'
rf$model <- 'Random Forest'

tree.outcomes <- rbind(xgb, basic, rf)
tree.outcomes
```

We considered Basic Regression, Random Forest and XGBoost tree models, and Random Forest performed the best in predicting PH as it had the smallest RMSE value at 0.1 and an R^2 of 0.695.

In this Random Forest model, these were the most important predictors:

```{r}
varImp(bevrf)
```

### Conclusion

```{r}
bev_eval <- read.xlsx("StudentEvaluation.xlsx", sheetName = "Subset (2)")
```

